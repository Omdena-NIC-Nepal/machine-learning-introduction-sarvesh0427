# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-tCcuq5c5_YqEnzcM9nyRTQ1hMMBiaIK
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("BostonHousing.csv")

print(df.isnull().sum())

print(df.info())

from sklearn.preprocessing import StandardScaler

# Normalize/standardize numerical features

target_col = 'medv'
X = df.drop(columns=[target_col])
y = df[target_col]

# Only apply scaling to numeric columns
numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns

# Initialize scaler
scaler = StandardScaler()

# Fit and transform
X_scaled = scaler.fit_transform(X[numeric_cols])

# Convert scaled array back to DataFrame
X_scaled_df = pd.DataFrame(X_scaled, columns=numeric_cols)

# Combining scaled features with target again if required
df_scaled = pd.concat([X_scaled_df, y], axis=1)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size = 0.2, random_state = 42)

print(X_train.shape)

print(y_train.shape)